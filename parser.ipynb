{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4164811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b00853",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GEMINI_API_KEY, MODEL_ID\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m genai\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from config import GEMINI_API_KEY, MODEL_ID\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import pathlib\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "system_prompt_qa = \"\"\" Act as a Q&A bot on Varsha' resumes to help fill job applications. Be very clear and say \"I do not know\" if you do not know the answer or cant back up with solid proof from the given resume pdfs\"\"\"\n",
    "chat_config = types.GenerateContentConfig(\n",
    "    system_instruction=system_prompt_qa,\n",
    ")\n",
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=chat_config,\n",
    ")\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "filepath_MLE = pathlib.Path('/content/Varsha Vattikonda - MLE.pdf')\n",
    "filepath_DS = pathlib.Path('/content/Varsha Vattikonda - DS.pdf')\n",
    "\n",
    "response = chat.send_message([\n",
    "      types.Part.from_bytes(\n",
    "        data=filepath_DS.read_bytes(),\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      types.Part.from_bytes(\n",
    "        data=filepath_MLE.read_bytes(),\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      \"What is the candidate's name\"])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c230c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
